# Use an official CUDA-enabled PyTorch image as the base image
FROM pytorch/pytorch:1.8.1-cuda11.1-cudnn8-runtime

# Set the working directory in the container
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    git wget libgl1-mesa-glx \
    && apt-get clean && rm -rf /var/lib/apt/lists/*

# Clone the Wav2Lip-HQ repository
RUN git clone https://github.com/Markfryazino/wav2lip-hq.git

# Change to the Wav2Lip-HQ directory
WORKDIR /app/wav2lip-hq

# Install Python dependencies
RUN pip install gdown "numpy>=1.19.5,<1.27.0"
RUN pip install -r requirements.txt

# Download face detection model
RUN mkdir -p face_detection/detection/sfd
RUN wget "https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth" -O "face_detection/detection/sfd/s3fd.pth"

# Create directory for checkpoints
RUN mkdir -p checkpoints

# Copy the download models script and run it
COPY download_models.py .
RUN chmod +x download_models.py
RUN python download_models.py

# Create directories for input and output videos
RUN mkdir -p videos results

# Set default values for environment variables
ENV AUDIO_PATH=audio/default_audio.webm
ENV FACE_PATH=videos/default_face.webm
ENV OUTPUT_PATH=results/default_output.mp4

# Copy the custom entrypoint script into the container and make it executable
COPY run_inference.sh .
RUN chmod +x run_inference.sh

# Use the custom entrypoint script as the container's entrypoint
ENTRYPOINT ["./run_inference.sh"]
